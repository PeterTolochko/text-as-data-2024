---
title: "Implementing input alignment via machine translation"
author: "Fabienne Lind"
date: "October, 2022"
output:
  html_document:
    df_print: paged
---

# Implementing input alignment via machine translation

## Data

For the next tasks, we will work with an example text data, headlines from news articles about migration. The data set is a subset of the [REMINDER media corpus](https://doi.org/10.11587/IEGQ1B).

Let's load the data first and take a look. Each row represents one news article. How many articles per country do we have?

```{r}

articles <- read.csv("https://raw.githubusercontent.com/fabiennelind/Workshop_Multilingual-Text-Analysis_and_Comparative-Research/master/data/multilingual_data_annotated.csv")

#as.data.frame(articles)
table(articles$country) 

```



Let us now inspect the column `headline`, the column with our text to be pre-processed. 

```{r}

head(articles$headline) # show the first lines of the column
class(articles$headline) # check the class of the column.
articles$headline <- as.character(articles$headline) # Change the class to character.
class(articles$headline) # check if the edit worked.

```

For our exercise, we work with the headlines of the corpus parts published in Germany, Spain, and the UK separately. Thus, we first need to apply a filter. To select a subset of the data, we can use for example `subset`. We save the German subset in dataframe objects called `articles_de`, the Spanish part in a dataframe called `articles_es`, the English part in a dataframe called `articles_en`.

```{r}

articles_de <- subset(articles, country == "Germany")
articles_es <- subset(articles, country == "Spain")
articles_en <- subset(articles, country == "UK")

```



## 1. Translation prize

One approach to process the multilingual documents all together is to translate them first into a common language (= input alignment). Translation can also be useful or necessary to be performed on keywords of a search string, keywords of a dictionary, codebook instructions, extracted Part-of-Speech etc. 

Next to manual translation, machine translation can be performed. 

- [DeepL](https://www.rstudio.com)

To calculate the prize beforehand, I recommend to count the number of characters first for example with `n_char`.

```{r}

#number of characters DE sample
n_char <- nchar(articles_de$headline)# whitespaces are also counted 
n_char_de <- sum(n_char, na.rm = T) 

#number of characters ES sample
n_char <- nchar(articles_es$headline)# whitespaces are also counted 
n_char_es <- sum(n_char, na.rm = T) 



#Calculate Prize
translation_prize_case <- (((n_char_de + n_char_es)/1000000)*20) #Neutral Translation Model Online Predictions (20 Dollar/1M Characters)
translation_prize_case 

```


## 2. Translation with the DeepL API

DeepL offers the [DeepL API Free](https://www.deepl.com/en/docs-api/) which allows a maximum of 500,000 characters/month to be translated for free. To use the API, it is necessary to create an account and provide your credit card details. After creating an account you will receive an Authentication Key (You find it your DeepL account settings). With [deeplr](https://github.com/zumbov2/deeplr) [(Zumbach & Bauer, 2021)](https://CRAN.R-project.org/package=deeplr), a new wrapper for the DeepL API it is easily possible to work with it from R. 


Put your API key in the quotes below: 

```{r}
my_key <- "put_your_API_key_here"
```

The much saver option however (recommended!) is to save an API key in the R environment. This way you do not share it directly in your script

How to do this: 
1. Set the environment variable. You need to do this only once. You can delete this line from your script later on.


```{r}
#Sys.setenv(GPT_API_KEY = "put_your_API_key_here")
```

2. Access the environment variable in your script. After storing the API key in your environment you can from now on call it with the following function.

```{r}
my_key <- Sys.getenv("GPT_API_KEY")
```





```{r}
#install.packages("deeplr")
library(deeplr)

#show available languages
#langs <- available_languages2("my_key") #Replace `my_key` with your Authentication Key.
#as.data.frame(langs)

#monitor your usage
#usage2("my_key") #Replace `my_key` with your Authentication Key.


```


This code will translate the text of column `headline_de` and `headline_es` and save the result in `headline_mt`. The source languages is guessed automatically if `source_lang = NULL`. The target language is here defined as `EN` = English.


```{r}

#translate DE to EN
#articles_de$headline_mt <- translate2(
#  articles_de$headline,
#  source_lang = DE, #if source_lang = NULL, the source language will be guessed
#  target_lang = "EN",
#  auth_key = "my_key" #Replace `my_key` with your Authentication Key.
#  )

as.data.frame(articles_de)

#translate ES to EN
#articles_es$headline_mt <- translate2(
#  articles_es$headline,
#  source_lang = ES, #if source_lang = NULL, the source language will be guessed
#  target_lang = "EN",
#  auth_key = "my_key" #Replace `my_key` with your Authentication Key.
#  )

# No need to translate the Uk subset of course

```

Just in case, with the following command you can just read in the translated headlines for you to move on to the next task (in case the translation did not work).

```{r}

articles <- read.csv("https://raw.githubusercontent.com/fabiennelind/Workshop_Multilingual-Text-Analysis_and_Comparative-Research/master/data/multilingual_data_annotated_translated.csv")

```

